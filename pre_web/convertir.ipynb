{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b17d4cd-ea2a-4625-b55f-b19120b31426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Cargando datos desde archivos .npy...\n",
      "✅ Datos cargados exitosamente:\n",
      "   - X shape: (60347, 63)\n",
      "   - y shape: (60347,)\n",
      "   - Clases únicas: 26 -> [np.str_('A'), np.str_('B'), np.str_('C'), np.str_('D'), np.str_('E'), np.str_('F'), np.str_('G'), np.str_('H'), np.str_('I'), np.str_('J'), np.str_('K'), np.str_('L'), np.str_('M'), np.str_('N'), np.str_('O'), np.str_('P'), np.str_('Q'), np.str_('R'), np.str_('S'), np.str_('T'), np.str_('U'), np.str_('V'), np.str_('W'), np.str_('X'), np.str_('Y'), np.str_('Z')]\n",
      "✅ Todas las 26 letras del alfabeto están presentes\n",
      "🔄 Normalizando landmarks...\n",
      "✅ Normalización completada\n",
      "📊 Estadísticas después de normalización:\n",
      "   - Min: -0.999995\n",
      "   - Max: 0.997852\n",
      "   - Mean: -0.194011\n",
      "   - Std: 0.313426\n",
      "\n",
      "🔄 Codificando etiquetas...\n",
      "✅ Etiquetas codificadas:\n",
      "   - Clases originales: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n",
      "   - Mapeo numérico: {np.str_('A'): 0, np.str_('B'): 1, np.str_('C'): 2, np.str_('D'): 3, np.str_('E'): 4, np.str_('F'): 5, np.str_('G'): 6, np.str_('H'): 7, np.str_('I'): 8, np.str_('J'): 9, np.str_('K'): 10, np.str_('L'): 11, np.str_('M'): 12, np.str_('N'): 13, np.str_('O'): 14, np.str_('P'): 15, np.str_('Q'): 16, np.str_('R'): 17, np.str_('S'): 18, np.str_('T'): 19, np.str_('U'): 20, np.str_('V'): 21, np.str_('W'): 22, np.str_('X'): 23, np.str_('Y'): 24, np.str_('Z'): 25}\n",
      "\n",
      "🔄 Dividiendo datos en entrenamiento y prueba...\n",
      "✅ División completada:\n",
      "   - Entrenamiento: 51294 muestras (85.0%)\n",
      "   - Prueba: 9053 muestras (15.0%)\n",
      "\n",
      "📊 Distribución de clases en entrenamiento:\n",
      "   A: 1859 muestras\n",
      "   B: 1876 muestras\n",
      "   C: 1690 muestras\n",
      "   D: 2093 muestras\n",
      "   E: 1962 muestras\n",
      "   F: 2444 muestras\n",
      "   G: 2074 muestras\n",
      "   H: 2034 muestras\n",
      "   I: 2026 muestras\n",
      "   J: 2191 muestras\n",
      "   K: 2295 muestras\n",
      "   L: 2148 muestras\n",
      "   M: 1330 muestras\n",
      "   N: 1085 muestras\n",
      "   O: 1925 muestras\n",
      "   P: 1736 muestras\n",
      "   Q: 1779 muestras\n",
      "   R: 2160 muestras\n",
      "   S: 2168 muestras\n",
      "   T: 1997 muestras\n",
      "   U: 2139 muestras\n",
      "   V: 2166 muestras\n",
      "   W: 2088 muestras\n",
      "   X: 1834 muestras\n",
      "   Y: 2197 muestras\n",
      "   Z: 1998 muestras\n",
      "\n",
      "🔄 Preparando datos para TensorFlow.js...\n",
      "✅ Datos preparados para TensorFlow.js:\n",
      "   - Forma de entrada: 63\n",
      "   - Número de clases: 26\n",
      "   - Muestras de entrenamiento: 51294\n",
      "   - Muestras de prueba: 9053\n",
      "\n",
      "🔄 Guardando archivos JSON...\n",
      "✅ Guardado: train_data.json\n",
      "✅ Guardado: model_info.json\n",
      "✅ Guardado: labels.json\n",
      "\n",
      "============================================================\n",
      "📋 RESUMEN FINAL\n",
      "============================================================\n",
      "📊 Estadísticas de datos:\n",
      "   • Total de muestras: 60,347\n",
      "   • Características por muestra: 63\n",
      "   • Clases únicas: 26\n",
      "   • Muestras de entrenamiento: 51,294\n",
      "   • Muestras de prueba: 9,053\n",
      "\n",
      "📁 Archivos generados:\n",
      "   • train_data.json (75.0 MB)\n",
      "   • model_info.json (0.9 KB)\n",
      "   • labels.json (0.3 KB)\n",
      "\n",
      "🎯 Alfabeto ASL completo:\n",
      "   A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\n",
      "\n",
      "✅ ¡Procesamiento completado exitosamente!\n",
      "   Los archivos están listos para usar con TensorFlow.js\n",
      "\n",
      "🔍 Verificando integridad de datos...\n",
      "✅ X_train no tiene valores NaN o infinitos\n",
      "✅ X_test no tiene valores NaN o infinitos\n",
      "✅ Etiquetas de entrenamiento en rango válido\n",
      "✅ Etiquetas de prueba en rango válido\n",
      "\n",
      "🎉 ¡Todo listo para entrenar con TensorFlow.js!\n"
     ]
    }
   ],
   "source": [
    "# Procesamiento de Datos ASL para TensorFlow.js\n",
    "# Cuaderno Jupyter para convertir archivos .npy a formato JSON\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "geo\n",
    "print(\"🔄 Cargando datos desde archivos .npy...\")\n",
    "\n",
    "# Cargar los datos (ajusta las rutas según tu estructura)\n",
    "X = np.load(\"X_hand_landmarks.npy\")\n",
    "y = np.load(\"y_labels.npy\")\n",
    "\n",
    "print(f\"✅ Datos cargados exitosamente:\")\n",
    "print(f\"   - X shape: {X.shape}\")\n",
    "print(f\"   - y shape: {y.shape}\")\n",
    "print(f\"   - Clases únicas: {len(np.unique(y))} -> {sorted(np.unique(y))}\")\n",
    "\n",
    "# Verificar que tenemos las 26 letras\n",
    "expected_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "                   'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "unique_classes = sorted(np.unique(y))\n",
    "\n",
    "if len(unique_classes) == 26 and unique_classes == expected_letters:\n",
    "    print(\"✅ Todas las 26 letras del alfabeto están presentes\")\n",
    "else:\n",
    "    print(f\"⚠️  Advertencia: Se esperaban 26 clases (A-Z), encontradas {len(unique_classes)}\")\n",
    "    print(f\"   Clases faltantes: {set(expected_letters) - set(unique_classes)}\")\n",
    "    print(f\"   Clases extra: {set(unique_classes) - set(expected_letters)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. FUNCIÓN DE NORMALIZACIÓN\n",
    "# ============================================================================\n",
    "\n",
    "def normalize_hand_landmarks(landmarks_batch):\n",
    "    \"\"\"\n",
    "    Normaliza los landmarks de la mano usando la muñeca como referencia\n",
    "    y escalando por la distancia máxima de los dedos\n",
    "    \"\"\"\n",
    "    print(\"🔄 Normalizando landmarks...\")\n",
    "    normalized_batch = np.zeros_like(landmarks_batch)\n",
    "    \n",
    "    for i in range(landmarks_batch.shape[0]):\n",
    "        landmarks = landmarks_batch[i].reshape(21, 3)  # 21 puntos, 3 coordenadas (x,y,z)\n",
    "        \n",
    "        # Usar la muñeca (punto 0) como punto de referencia\n",
    "        wrist = landmarks[0].copy()\n",
    "        landmarks_relative = landmarks - wrist\n",
    "        \n",
    "        # Calcular escala usando los dedos (excluyendo muñeca)\n",
    "        finger_points = landmarks_relative[1:]  # Todos excepto la muñeca\n",
    "        distances = np.linalg.norm(finger_points, axis=1)\n",
    "        max_distance = np.max(distances)\n",
    "        \n",
    "        # Normalizar si hay movimiento significativo\n",
    "        if max_distance > 1e-6:\n",
    "            landmarks_relative = landmarks_relative / max_distance\n",
    "        \n",
    "        normalized_batch[i] = landmarks_relative.flatten()\n",
    "    \n",
    "    print(f\"✅ Normalización completada\")\n",
    "    return normalized_batch\n",
    "\n",
    "# Aplicar normalización\n",
    "X_normalized = normalize_hand_landmarks(X)\n",
    "\n",
    "print(f\"📊 Estadísticas después de normalización:\")\n",
    "print(f\"   - Min: {X_normalized.min():.6f}\")\n",
    "print(f\"   - Max: {X_normalized.max():.6f}\")\n",
    "print(f\"   - Mean: {X_normalized.mean():.6f}\")\n",
    "print(f\"   - Std: {X_normalized.std():.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CODIFICACIÓN DE ETIQUETAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔄 Codificando etiquetas...\")\n",
    "\n",
    "# Crear el codificador de etiquetas\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"✅ Etiquetas codificadas:\")\n",
    "print(f\"   - Clases originales: {le.classes_}\")\n",
    "print(f\"   - Mapeo numérico: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DIVISIÓN DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔄 Dividiendo datos en entrenamiento y prueba...\")\n",
    "\n",
    "# División estratificada para mantener proporción de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y_encoded, \n",
    "    test_size=0.15,        # 15% para prueba, 85% para entrenamiento\n",
    "    random_state=42,       # Para reproducibilidad\n",
    "    stratify=y_encoded     # Mantener proporción de clases\n",
    ")\n",
    "\n",
    "print(f\"✅ División completada:\")\n",
    "print(f\"   - Entrenamiento: {X_train.shape[0]} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Prueba: {X_test.shape[0]} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verificar distribución de clases\n",
    "print(f\"\\n📊 Distribución de clases en entrenamiento:\")\n",
    "train_unique, train_counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(train_unique, train_counts):\n",
    "    letter = le.classes_[label]\n",
    "    print(f\"   {letter}: {count} muestras\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. PREPARAR DATOS PARA TENSORFLOW.JS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔄 Preparando datos para TensorFlow.js...\")\n",
    "\n",
    "# Convertir a listas para serialización JSON\n",
    "train_data = {\n",
    "    \"X_train\": X_train.tolist(),\n",
    "    \"y_train\": y_train.tolist(),\n",
    "    \"X_test\": X_test.tolist(),\n",
    "    \"y_test\": y_test.tolist()\n",
    "}\n",
    "\n",
    "# Información del modelo\n",
    "model_info = {\n",
    "    \"input_shape\": int(X_train.shape[1]),\n",
    "    \"num_classes\": int(len(le.classes_)),\n",
    "    \"classes\": le.classes_.tolist(),\n",
    "    \"label_mapping\": {str(i): label for i, label in enumerate(le.classes_)},\n",
    "    \"train_samples\": int(X_train.shape[0]),\n",
    "    \"test_samples\": int(X_test.shape[0]),\n",
    "    \"total_samples\": int(len(X)),\n",
    "    \"features_per_sample\": int(X_train.shape[1]),\n",
    "    \"normalization_method\": \"hand_landmarks_relative_to_wrist_scaled\"\n",
    "}\n",
    "\n",
    "print(f\"✅ Datos preparados para TensorFlow.js:\")\n",
    "print(f\"   - Forma de entrada: {model_info['input_shape']}\")\n",
    "print(f\"   - Número de clases: {model_info['num_classes']}\")\n",
    "print(f\"   - Muestras de entrenamiento: {model_info['train_samples']}\")\n",
    "print(f\"   - Muestras de prueba: {model_info['test_samples']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. GUARDAR ARCHIVOS JSON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔄 Guardando archivos JSON...\")\n",
    "\n",
    "# Guardar datos de entrenamiento\n",
    "with open(\"train_data.json\", \"w\") as f:\n",
    "    json.dump(train_data, f)\n",
    "print(\"✅ Guardado: train_data.json\")\n",
    "\n",
    "# Guardar información del modelo\n",
    "with open(\"model_info.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
    "print(\"✅ Guardado: model_info.json\")\n",
    "\n",
    "# Guardar solo el mapeo de etiquetas (útil para inferencia)\n",
    "label_mapping = {str(i): label for i, label in enumerate(le.classes_)}\n",
    "with open(\"labels.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(label_mapping, f, indent=2, ensure_ascii=False)\n",
    "print(\"✅ Guardado: labels.json\")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. VERIFICACIÓN Y ESTADÍSTICAS FINALES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 RESUMEN FINAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"📊 Estadísticas de datos:\")\n",
    "print(f\"   • Total de muestras: {len(X):,}\")\n",
    "print(f\"   • Características por muestra: {X_train.shape[1]}\")\n",
    "print(f\"   • Clases únicas: {len(le.classes_)}\")\n",
    "print(f\"   • Muestras de entrenamiento: {X_train.shape[0]:,}\")\n",
    "print(f\"   • Muestras de prueba: {X_test.shape[0]:,}\")\n",
    "\n",
    "print(f\"\\n📁 Archivos generados:\")\n",
    "print(f\"   • train_data.json ({os.path.getsize('train_data.json')/1024/1024:.1f} MB)\")\n",
    "print(f\"   • model_info.json ({os.path.getsize('model_info.json')/1024:.1f} KB)\")\n",
    "print(f\"   • labels.json ({os.path.getsize('labels.json')/1024:.1f} KB)\")\n",
    "\n",
    "print(f\"\\n🎯 Alfabeto ASL completo:\")\n",
    "print(\"   \" + \" \".join(le.classes_))\n",
    "\n",
    "print(f\"\\n✅ ¡Procesamiento completado exitosamente!\")\n",
    "print(f\"   Los archivos están listos para usar con TensorFlow.js\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. OPCIONAL: VERIFICAR INTEGRIDAD DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔍 Verificando integridad de datos...\")\n",
    "\n",
    "# Verificar que no hay valores NaN o infinitos\n",
    "if np.any(np.isnan(X_train)) or np.any(np.isinf(X_train)):\n",
    "    print(\"⚠️  Advertencia: Se encontraron valores NaN o infinitos en X_train\")\n",
    "else:\n",
    "    print(\"✅ X_train no tiene valores NaN o infinitos\")\n",
    "\n",
    "if np.any(np.isnan(X_test)) or np.any(np.isinf(X_test)):\n",
    "    print(\"⚠️  Advertencia: Se encontraron valores NaN o infinitos en X_test\")\n",
    "else:\n",
    "    print(\"✅ X_test no tiene valores NaN o infinitos\")\n",
    "\n",
    "# Verificar rangos de etiquetas\n",
    "if np.min(y_train) >= 0 and np.max(y_train) < len(le.classes_):\n",
    "    print(\"✅ Etiquetas de entrenamiento en rango válido\")\n",
    "else:\n",
    "    print(\"⚠️  Advertencia: Etiquetas de entrenamiento fuera de rango\")\n",
    "\n",
    "if np.min(y_test) >= 0 and np.max(y_test) < len(le.classes_):\n",
    "    print(\"✅ Etiquetas de prueba en rango válido\")\n",
    "else:\n",
    "    print(\"⚠️  Advertencia: Etiquetas de prueba fuera de rango\")\n",
    "\n",
    "print(\"\\n🎉 ¡Todo listo para entrenar con TensorFlow.js!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a5f31-8786-422d-874e-ee4cf2c4728c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
